apiVersion: v1
kind: Service
metadata:
  name: ml-inference-service
  namespace: inference
  labels:
    app: ml-inference-service
spec:
  externalTrafficPolicy: Local
  type: NodePort
  selector:
    app: ml-inference-v1
  ports:
    - name: http
      protocol: TCP
      port: 8080
      targetPort: 8080
      nodePort: 8080
